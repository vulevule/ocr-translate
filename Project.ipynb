{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekat - Prevodilac\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 # OpenCV\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from skimage.filters import threshold_local\n",
    "from googletrans import Translator\n",
    "import pytesseract\n",
    "#pytesseract.pytesseract.tesseract_cmd = r'/home/student/anaconda3/lib/python3.6/site-packages/pytesseract/pytesseract.py'\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# iscrtavanje slika u notebook-u\n",
    "%matplotlib inline\n",
    "# prikaz vecih slika\n",
    "matplotlib.rcParams['figure.figsize'] = 20,16\n",
    "\n",
    "# keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#scikit\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_image(path):\n",
    "    return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def image_gray(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def image_bin(image_gs):\n",
    "    height, width = image_gs.shape[0:2]\n",
    "    image_binary = np.ndarray((height, width), dtype=np.uint8)\n",
    "    ret, image_bin = cv2.threshold(image_gs, 127, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "    return image_bin\n",
    "\n",
    "def invert(image):\n",
    "    return 255-image\n",
    "\n",
    "def display_image(image, color=False, aspect='equal'):\n",
    "    if color:\n",
    "        plt.imshow(image, aspect=aspect)\n",
    "    else:\n",
    "        plt.imshow(image, 'gray', aspect=aspect)\n",
    "\n",
    "def dilate(image):\n",
    "    kernel = np.ones((3, 3)) # strukturni element 3x3 blok\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "def erode(image):\n",
    "    kernel = np.ones((3, 3)) # strukturni element 3x3 blok\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "def preprocess(img, blur=\"none\", thr=\"otsu\", remove_noise=True):\n",
    "    if blur == \"median\":\n",
    "        img = cv2.medianBlur(img,5)\n",
    "    elif blur == \"gauss\":\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        \n",
    "    img = image_gray(img)\n",
    "    \n",
    "    if thr == \"otsu\":\n",
    "        ret,img = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    elif thr == \"mean\":\n",
    "        img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    elif thr == \"gauss\":\n",
    "        img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    elif thr == \"scikit\":\n",
    "        T = threshold_local(img, 11, offset = 10, method = \"gaussian\")\n",
    "        img = (img > T).astype(\"uint8\") * 255\n",
    "    else:\n",
    "        img = image_bin(img)\n",
    "    \n",
    "#     if remove_noise == True:\n",
    "#         if invert_image:\n",
    "#             img = dilate(erode(img))\n",
    "#         else:\n",
    "#             img = erode(dilate(img))\n",
    "    \n",
    "#     if invert_image:\n",
    "#         img = invert(img)\n",
    "    \n",
    "    if remove_noise == True:\n",
    "        img = dilate(erode(img))\n",
    "    \n",
    "    img = invert(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def resize_region(region):\n",
    "    return cv2.resize(region, (28, 28), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "def scale_to_range(image):\n",
    "    return image/255\n",
    "\n",
    "def matrix_to_vector(image):\n",
    "    return image.flatten()\n",
    "\n",
    "def prepare_for_ann(regions):\n",
    "    ready_for_ann = []\n",
    "    for region in regions:\n",
    "        scale = scale_to_range(region)\n",
    "        ready_for_ann.append(matrix_to_vector(scale))\n",
    "    return ready_for_ann\n",
    "\n",
    "def convert_output(alphabet):\n",
    "    nn_outputs = []\n",
    "    for index in range(len(alphabet)):\n",
    "        output = np.zeros(len(alphabet))\n",
    "        output[index] = 1\n",
    "        nn_outputs.append(output)\n",
    "    return np.array(nn_outputs)\n",
    "\n",
    "def create_ann(output_size):\n",
    "    ann = Sequential()\n",
    "    ann.add(Dense(128, input_dim=784, activation='sigmoid'))\n",
    "    ann.add(Dense(output_size, activation='sigmoid'))\n",
    "    return ann\n",
    "\n",
    "def train_ann(ann, X_train, y_train, epochs):\n",
    "    X_train = np.array(X_train, np.float32) # dati ulaz\n",
    "    y_train = np.array(y_train, np.float32) # zeljeni izlazi na date ulaze\n",
    "    \n",
    "    print(\"\\nTraining started...\")\n",
    "    sgd = SGD(lr=0.01, momentum=0.9)\n",
    "    ann.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "    ann.fit(X_train, y_train, epochs=epochs, batch_size=1, verbose=0, shuffle=False)\n",
    "    print(\"\\nTraining completed...\")\n",
    "    return ann\n",
    "\n",
    "def winner(output):\n",
    "    return max(enumerate(output), key=lambda x: x[1])\n",
    "\n",
    "def get_contour_precedence(origin, cols):\n",
    "    tolerance_factor = 10\n",
    "    #temp = origin[1] + origin[3]/2\n",
    "    return ((origin[1] // tolerance_factor) * tolerance_factor) * cols + origin[0]\n",
    "\n",
    "def sort_regions_sophisticated(regions):\n",
    "    regions = sorted(regions, key=lambda x: x[1][1])\n",
    "    breaks = [0]\n",
    "    \n",
    "    for i in range(len(regions)-1):\n",
    "        current_reg = regions[i]\n",
    "        next_reg = regions[i+1]\n",
    "        if(next_reg[1][1] > (current_reg[1][1]+current_reg[1][3])):\n",
    "            breaks.append(i+1)\n",
    "\n",
    "    breaks.append(len(regions))\n",
    "    \n",
    "    for i in range(len(breaks)-1):\n",
    "        regions[breaks[i]:breaks[i+1]] = sorted(regions[breaks[i]:breaks[i+1]], key=lambda x: x[1][0])\n",
    "    \n",
    "    return regions\n",
    "    \n",
    "def get_words(image_bin, regions):\n",
    "    imgh, imgw = image_bin.shape[0:2]\n",
    "    maxh = max(regions, key=lambda x: x[1][3])[1][3]\n",
    "    count = 0\n",
    "    words = []\n",
    "    expected_contours = imgh // (maxh*1.2) # ocekivani broj redova, uzmimo da se tekst nalazi blizu ivica: visina slike / najveca visina slova povecana za razmak\n",
    "    \n",
    "    while True:\n",
    "        image_bin = dilate(image_bin)  \n",
    "        img, contours, hierarchy = cv2.findContours(image_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        words = []\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 50 and h > 10 and w > 5:   \n",
    "                words.append((x, y, w, h))\n",
    "                #cv2.rectangle(image_orig, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        count = len(words)\n",
    "        \n",
    "        if count >= expected_contours-2 or count <= expected_contours+2:\n",
    "            return words\n",
    "            \n",
    "\n",
    "def sort_regions(image_bin, regions):\n",
    "    words = get_words(image_bin, regions)\n",
    "    words = sorted(words, key=lambda x: get_contour_precedence(x, image_bin.shape[1]))\n",
    "    sorted_regions = []\n",
    "    \n",
    "    for word in words:\n",
    "        word_array = []\n",
    "        idxs = []\n",
    "        for idx,region in enumerate(regions):  \n",
    "            if region[1][0] > word[0] and (region[1][0]+region[1][2]) < (word[0]+word[2]) and region[1][1] > word[1] and (region[1][1]+region[1][3]) < (word[1]+word[3]):\n",
    "                word_array.append(region)\n",
    "                idxs.append(idx)\n",
    "                \n",
    "        word_array = sorted(word_array, key=lambda x: x[1][0])\n",
    "        sorted_regions.extend(word_array)\n",
    "        \n",
    "        regions = [reg for idx,reg in enumerate(regions) if idx not in idxs]\n",
    "        \n",
    "    return sorted_regions\n",
    "\n",
    "def crop_and_warp(original, img):\n",
    "    preprocessed = img.copy()\n",
    "    imgh, imgw = img.shape[0:2]\n",
    "    img_size = imgh*imgw\n",
    "    regions = []\n",
    "\n",
    "    while True:\n",
    "        regions = []\n",
    "        img = dilate(img)\n",
    "        image, contours, hierarchy = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            #x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "            w = rect[1][0]\n",
    "            h = rect[1][1]\n",
    "            box = cv2.boxPoints(rect)\n",
    "\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > img_size*0.1 or w > imgw*0.2 or h > imgh*0.1: \n",
    "                regions.append((box, area))\n",
    "                #cv2.rectangle(image_orig, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        if len(regions) == 0:\n",
    "            continue\n",
    "\n",
    "        regions = sorted(regions, key=lambda x: x[1])\n",
    "        max_reg = regions[-1]\n",
    "        if max_reg[1] > img_size*0.6:\n",
    "            break\n",
    "\n",
    "    box = max_reg[0]\n",
    "    box = np.int0(box)\n",
    "    cv2.drawContours(original,[box],-1,(0,255,0),3)\n",
    "    rect = order_points(box)\n",
    "    cropped = warp_perspective(preprocessed, rect)\n",
    "\n",
    "    return cropped\n",
    "\n",
    "def handle_kukice(image_bin, regions_array, sort=\"smart\"):\n",
    "    regions_temp = []\n",
    "    region_heights = [region[1][3] for region in regions_array]\n",
    "    region_heights = np.array(region_heights).reshape(len(region_heights), 1)\n",
    "    k_means = KMeans(n_clusters=2, max_iter=2000, tol=0.00001, n_init=10)\n",
    "    \n",
    "    try:\n",
    "        k_means.fit(region_heights)\n",
    "    except Exception:\n",
    "        return regions_array\n",
    "    \n",
    "    kukice_group = min(enumerate(k_means.cluster_centers_), key=lambda x: x[1])[0]\n",
    "    idx_to_avoid = []\n",
    "    for idx, reg in enumerate(regions_array):\n",
    "        if k_means.labels_[idx] == kukice_group:\n",
    "            found = False\n",
    "            for idx_search, reg_search in enumerate(regions_array):\n",
    "                if reg_search[1][0] != reg[1][0] and reg_search[1][1] != reg[1][1]:\n",
    "                    if reg[1][0] > (reg_search[1][0]-reg[1][2]/2) and (reg[1][0]+reg[1][2]) < (reg_search[1][0]+reg_search[1][2]+reg[1][2]/2) and (reg_search[1][1]-reg[1][1]-reg[1][3]) < (reg_search[1][3]*0.5) and reg[1][3] < reg_search[1][3]:\n",
    "                        newx = reg_search[1][0]\n",
    "                        newy = reg[1][1]\n",
    "                        neww = reg_search[1][2]\n",
    "                        newh = reg_search[1][1] + reg_search[1][3] - reg[1][1]\n",
    " \n",
    "                        region = image_bin[newy:newy+newh+1, newx:newx+neww+1]\n",
    "                        \n",
    "                        # print(\"Shape\", region.shape[0:2])\n",
    "                        try:\n",
    "                            regions_temp.append([resize_region(region), (newx, newy, neww, newh)])\n",
    "                            idx_to_avoid.append(idx_search)\n",
    "                            idx_to_avoid.append(idx)\n",
    "                            \n",
    "                            found = True\n",
    "                        except Exception:\n",
    "                            pass\n",
    "    \n",
    "    # izbacivanje starih\n",
    "    regions_array = [reg for idx,reg in enumerate(regions_array) if idx not in idx_to_avoid]\n",
    "    regions_array.extend(regions_temp)\n",
    "    \n",
    "    # sortiranje\n",
    "    if sort == \"smart\":\n",
    "        regions_array = sort_regions_sophisticated(regions_array)\n",
    "    else:\n",
    "        regions_array = sort_regions(image_bin, regions_array)\n",
    "    \n",
    "    return regions_array\n",
    "    \n",
    "def draw_regions(image_orig, regions_array):\n",
    "    for idx,reg in enumerate(regions_array):\n",
    "        cv2.rectangle(image_orig, (reg[1][0], reg[1][1]), (reg[1][0]+reg[1][2], reg[1][1]+reg[1][3]), (0, 255, 0), 2)\n",
    "        cv2.putText(image_orig, str(idx),(reg[1][0]-5, reg[1][1]), cv2.FONT_HERSHEY_SIMPLEX, 0.8,(0,255,0),1,cv2.LINE_AA)\n",
    "\n",
    "def get_distances(regions_array):\n",
    "    region_distances = []\n",
    "    sorted_rectangles = [region[1] for region in regions_array]\n",
    "    # izdvojiti sortirane parametre opisujucih pravougaonika\n",
    "    # izracunati rastojanja izmedju svih susednih regiona po X osi i dodati ih u niz rastojanja\n",
    "    for index in range(0, len(sorted_rectangles) - 1):\n",
    "        current = sorted_rectangles[index]\n",
    "        next_rect = sorted_rectangles[index + 1]\n",
    "        distance = abs(next_rect[0] - (current[0] + current[2])) # x_next - (x_current + w_current)\n",
    "        region_distances.append(distance)\n",
    "        \n",
    "    return region_distances;\n",
    "    \n",
    "def select_roi_with_distances(image_orig, image_bin, kukice=True, sort=\"smart\"):\n",
    "    img, contours, hierarchy = cv2.findContours(image_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    regions_array = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 50 and h > 10 and w > 5:\n",
    "            region = image_bin[y:y+h+1, x:x+w+1]\n",
    "            regions_array.append([resize_region(region), (x, y, w, h)])\n",
    "            #cv2.rectangle(image_orig, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "    #draw_regions(image_orig, regions_array)\n",
    "    \n",
    "    # sortiranje\n",
    "    if sort == \"smart\":\n",
    "        regions_array = sort_regions_sophisticated(regions_array)\n",
    "    else:\n",
    "        regions_array = sort_regions(image_bin, regions_array)\n",
    "    \n",
    "    # pronalazenje kukica i dodavanje na slova\n",
    "    if kukice:\n",
    "        regions_array = handle_kukice(image_bin, regions_array, sort)\n",
    "    \n",
    "    # obelezavanje regiona\n",
    "    draw_regions(image_orig, regions_array)\n",
    "    \n",
    "    sorted_regions = [region[0] for region in regions_array]\n",
    "    bounding_rects = [region[1] for region in regions_array]\n",
    "    region_distances = get_distances(regions_array)\n",
    "    \n",
    "    return image_orig, sorted_regions, bounding_rects, region_distances\n",
    "\n",
    "def display_result_with_spaces(outputs, alphabet, k_means, img, contours, display=True):\n",
    "    # odredjivanje indeksa grupe koja odgovara rastojanju izmedju reci\n",
    "    w_new_line_group = sorted(enumerate(k_means.cluster_centers_), key=lambda x: x[1])[-1][0]\n",
    "    w_space_group = sorted(enumerate(k_means.cluster_centers_), key=lambda x: x[1])[-2][0]\n",
    "    result = alphabet[winner(outputs[0])[0]]\n",
    "    # iterativno dodavanje prepoznatih elemenata\n",
    "    # dodavanje space karaktera ako je rastojanje izmedju dva slova odgovara rastojanju izmedju reci\n",
    "    for idx, output in enumerate(outputs[1:, :]):\n",
    "        if k_means.labels_[idx] == w_new_line_group:\n",
    "            result += '\\n'\n",
    "        elif k_means.labels_[idx] == w_space_group:\n",
    "            result += ' '\n",
    "        result_index, result_percentage = winner(output)\n",
    "        result_letter = alphabet[result_index]\n",
    "        result += result_letter\n",
    "        \n",
    "        if display:\n",
    "            reg = contours[idx]\n",
    "            cv2.rectangle(img, (reg[0], reg[1]), (reg[0]+reg[2], reg[1]+reg[3]), (0, 0, 255), 2)\n",
    "            cv2.putText(img, result_letter+\": \"+str(result_percentage), (reg[0]-10, reg[1]), cv2.FONT_HERSHEY_SIMPLEX, 1.2,(0,0,255),2,cv2.LINE_AA)\n",
    "    return result\n",
    "\n",
    "def display_result_with_spaces_only(outputs, alphabet, k_means):    \n",
    "    w_space_group = max(enumerate(k_means.cluster_centers_), key=lambda x: x[1])[0]\n",
    "    result = alphabet[winner(outputs[0])]\n",
    "    for idx, output in enumerate(outputs[1:, :]):\n",
    "        if k_means.labels_[idx] == w_space_group:\n",
    "            result += ' '\n",
    "        result += alphabet[winner(output)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective warping methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners(image):\n",
    "    img = image.copy()\n",
    "    for i in range(20):\n",
    "        img = dilate(img)\n",
    "    \n",
    "    display_image(img)\n",
    "    img, contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    regions_array = []\n",
    "    for contour in contours:\n",
    "        # x, y, w, h = cv2.boundingRect(contour)\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        w = rect[1][0]\n",
    "        h = rect[1][1]\n",
    "        box = cv2.boxPoints(rect)\n",
    "        \n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 50 and h < 150 and h > 10 and w > 5:\n",
    "            regions_array.extend(box)\n",
    "    \n",
    "    regions_x = sorted(regions_array, key=lambda x: x[0])\n",
    "    regions_y = sorted(regions_array, key=lambda x: x[1])\n",
    "    \n",
    "    minx = regions_x[0]\n",
    "    maxx = regions_x[-1]\n",
    "    miny = regions_y[0]\n",
    "    maxy = regions_y[-1]\n",
    "    \n",
    "    return [minx, maxx, miny, maxy]\n",
    "\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    return rect\n",
    "\n",
    "def warp_perspective(image, pts):\n",
    "    # rect = order_points(pts)\n",
    "    rect = pts\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_testing():\n",
    "    # test resize \n",
    "    test_resize_img = load_image('images/test_resize.png')\n",
    "    test_resize_ref = (28, 28)\n",
    "    test_resize_res = resize_region(test_resize_img).shape[0:2]\n",
    "    print(\"Test resize passsed: \", test_resize_res == test_resize_ref)\n",
    "\n",
    "    # test scale\n",
    "    test_scale_matrix = np.array([[0, 255], [51, 153]], dtype='float')\n",
    "    test_scale_ref = np.array([[0., 1.], [0.2, 0.6]], dtype='float')\n",
    "    test_scale_res = scale_to_range(test_scale_matrix)\n",
    "    print(\"Test scale passed: \", np.array_equal(test_scale_res, test_scale_ref))\n",
    "\n",
    "    # test matrix to vector\n",
    "    test_mtv = np.ndarray((28, 28))\n",
    "    test_mtv_ref = (784, )\n",
    "    test_mtv_res = matrix_to_vector(test_mtv).shape\n",
    "    print(\"Test matrix to vector passed: \", test_mtv_res == test_mtv_ref)\n",
    "\n",
    "    # test convert\n",
    "    test_convert_alphabet = [0, 1, 2]\n",
    "    test_convert_ref = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype='float')\n",
    "    test_convert_res = convert_output(test_convert_alphabet).astype('float')\n",
    "    print(\"Test convert output: \", np.array_equal(test_convert_res, test_convert_ref))\n",
    "\n",
    "    # test winner\n",
    "    test_winner_output = [0., 0.2, 0.3, 0.95]\n",
    "    test_winner_ref = 3\n",
    "    test_winner_res = winner(test_winner_output)[0]\n",
    "    print(\"Test winner passed: \", test_winner_res == test_winner_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(scope):\n",
    "    alphabet = \"QWERTYUIOPASDFGHJKLZXCVBNMŠĐČĆŽqwertyuiopasdfghjklzxcvbnmšđčćž0123456789\"\n",
    "    alphabet = [c for c in alphabet]\n",
    "    outputs = convert_output(alphabet)\n",
    "    ann = create_ann(len(alphabet))\n",
    "    for i in range(1,scope+1):\n",
    "        file_name = \"train/train\" + str(i) + \".png\"\n",
    "        try:\n",
    "            image_color = load_image(file_name) # 1,2,3,4,5\n",
    "        except Exception:\n",
    "            print(\"File \" + file_name + \" not found!\")\n",
    "            continue\n",
    "        img = preprocess(image_color)\n",
    "\n",
    "        selected, letters, contours, distances = select_roi_with_distances(image_color, img)\n",
    "        #display_image(selected)\n",
    "\n",
    "        if len(letters) != len(alphabet):\n",
    "            print(\"Letters and alphabet size dont match for file\", file_name)\n",
    "            continue\n",
    "\n",
    "        inputs = prepare_for_ann(letters)\n",
    "        print(\"\\nTrain for\", file_name)\n",
    "        ann = train_ann(ann, inputs, outputs, 2000)\n",
    "        \n",
    "    return ann\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_magic(ann, file_name, display=True, thr=\"otsu\", blur=\"none\", remove_noise=True):\n",
    "    image_color = load_image(file_name)\n",
    "    img = preprocess(image_color.copy(), blur, thr, remove_noise)\n",
    "\n",
    "    cropped = crop_and_warp(image_color, img)\n",
    "\n",
    "    selected, letters, contours, distances = select_roi_with_distances(image_color.copy(), cropped)\n",
    "    \n",
    "    if(len(letters) == 0):\n",
    "        #img = preprocess(image_color.copy(), blur, thr, remove_noise, invert_image=False)\n",
    "        img = invert(img)\n",
    "        cropped = crop_and_warp(image_color, img)\n",
    "        selected, letters, contours, distances = select_roi_with_distances(image_color.copy(), cropped)\n",
    "    \n",
    "    if display:\n",
    "        display_image(image_color)\n",
    "\n",
    "    distances = np.array(distances).reshape(len(distances), 1)\n",
    "    k_means = KMeans(n_clusters=3, max_iter=2000, tol=0.00001, n_init=10)\n",
    "    inputs = prepare_for_ann(letters)\n",
    "    alphabet = \"QWERTYUIOPASDFGHJKLZXCVBNMŠĐČĆŽqwertyuiopasdfghjklzxcvbnmšđčćž0123456789\"\n",
    "    alphabet = [c for c in alphabet]\n",
    "    try:\n",
    "        k_means.fit(distances)\n",
    "    except Exception:\n",
    "        print(\"Image not suitable for text extraction. Try again :)\")\n",
    "        return \"\"\n",
    "        \n",
    "    result = ann.predict(np.array(inputs, np.float32))\n",
    "    return display_result_with_spaces(result, alphabet, k_means, image_color, contours)\n",
    "\n",
    "def do_tesseract(file_name):\n",
    "    image_color = load_image(file_name)\n",
    "    display_image(image_color)\n",
    "    text = pytesseract.image_to_string(image_color)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, src=\"en\", dest=\"sr\"):\n",
    "    translator = Translator()\n",
    "    result = translator.translate(text, src=src, dest=dest)\n",
    "    return result.text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train for train/train1.png\n",
      "\n",
      "Training started...\n"
     ]
    }
   ],
   "source": [
    "ann = do_training(6) # parametar metode je koliko trening fajlova da se pokrije"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"test/test1.jpg\"\n",
    "text = do_magic(ann, file_name)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translate(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
